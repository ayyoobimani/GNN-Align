{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys\n",
    "sys.path.insert(0, '../')\n",
    "from my_utils import gpu_utils\n",
    "import importlib, gc\n",
    "from my_utils.alignment_features import *\n",
    "import my_utils.alignment_features as afeatures\n",
    "importlib.reload(afeatures)\n",
    "import gnn_utils.graph_utils as gutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-geometric\n",
    "# !pip install tensorboardX\n",
    "\n",
    "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "# !unzip ngrok-stable-linux-amd64.zip\n",
    "\n",
    "#  print(torch.version.cuda)\n",
    "#  print(torch.__version__)    \n",
    "\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24159\n"
     ]
    }
   ],
   "source": [
    "from my_utils import align_utils as autils, utils\n",
    "import argparse\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "\n",
    "# set random seed\n",
    "config_file = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc-ui-demo/config_pbc.ini\"\n",
    "utils.setup(config_file)\n",
    "\n",
    "params = argparse.Namespace()\n",
    "\n",
    "\n",
    "params.gold_file = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi-fin-grc-gold-alignments_train.txt\"\n",
    "pros, surs = autils.load_gold(params.gold_file)\n",
    "all_verses = list(pros.keys())\n",
    "params.gold_file = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi-fin-heb-gold-alignments_train.txt\"\n",
    "pros, surs = autils.load_gold(params.gold_file)\n",
    "all_verses.extend(list(pros.keys()))\n",
    "all_verses = list(set(all_verses))\n",
    "print(len(all_verses))\n",
    "\n",
    "params.editions_file =  \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi_lang_list.txt\"\n",
    "editions, langs = autils.load_simalign_editions(params.editions_file)\n",
    "current_editions = [editions[lang] for lang in langs]\n",
    "\n",
    "def get_pruned_verse_alignments(args):\n",
    "    verse, current_editions = args\n",
    "    \n",
    "    verse_aligns_inter = autils.get_verse_alignments(verse)\n",
    "    verse_aligns_gdfa = autils.get_verse_alignments(verse, gdfa=True)\n",
    "\n",
    "    autils.prune_non_necessary_alignments(verse_aligns_inter, current_editions)\n",
    "    autils.prune_non_necessary_alignments(verse_aligns_gdfa, current_editions)\n",
    "\n",
    "    gc.collect()\n",
    "    return verse_aligns_inter, verse_aligns_gdfa\n",
    "    \n",
    "\n",
    "verse_alignments_inter = {}\n",
    "verse_alignments_gdfa = {}\n",
    "args = []\n",
    "for i,verse in enumerate(all_verses):\n",
    "    args.append((verse, current_editions[:]))\n",
    "\n",
    "#print('going to get alignments')\n",
    "#with Pool(20) as p:\n",
    "#    all_res = p.map(get_pruned_verse_alignments, args)\n",
    "\n",
    "#for i,verse in enumerate(all_verses):\n",
    "#    verse_aligns_inter, verse_aligns_gdfa = all_res[i]\n",
    "    \n",
    "    #verse_alignments_inter[verse] = verse_aligns_inter\n",
    "    #verse_alignments_gdfa[verse] = verse_aligns_gdfa\n",
    "\n",
    "#utils.LOG.info(\"done reading alignments\")\n",
    "#torch.save(verse_alignments_inter, \"/mounts/work/ayyoob/models/gnn/pruned_alignments_train_inter.pickle\")\n",
    "#torch.save(verse_alignments_gdfa, \"/mounts/work/ayyoob/models/gnn/pruned_alignments_train_gdfa.pickle\")\n",
    "#utils.LOG.info('done saving pruned alignments')\n",
    "\n",
    "\n",
    "#print('reading inter verse alignments')\n",
    "#verse_alignments_inter = torch.load(\"/mounts/work/ayyoob/models/gnn/pruned_alignments_train_inter.pickle\")\n",
    "#gc.collect()\n",
    "#print('done reading inter verse alignments')\n",
    "\n",
    "#for verse in all_verses[:]:\n",
    "#    if len(verse_alignments_inter[verse].keys()) < 10:\n",
    "#        all_verses.remove(verse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-15\n",
    "\n",
    "def _diag(x):\n",
    "    eye = torch.eye(x.size(0)).type_as(x)\n",
    "    out = eye * x.unsqueeze(1).expand(x.size(0), x.size(0))\n",
    "    return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, edge_features, n_cluster=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        #self.feature_encoder = afeatures.FeatureEncoding(edge_features)\n",
    "        self.features_size = sum([x.out_dim for x in edge_features])\n",
    "        self.representataion_size = (input_size - self.features_size)\n",
    "\n",
    "        self.transfer = nn.Sequential(nn.Linear(input_size, hidden_size*2), nn.ReLU(), nn.Dropout(drop_out),\n",
    "                            #nn.Linear(hidden_size*2, hidden_size), nn.ReLU(), nn.Dropout(drop_out),\n",
    "                            nn.Linear(hidden_size*2, 1))\n",
    "\n",
    "        #self.transfer = nn.Sequential(nn.ELU(), nn.Linear(n_cluster*2, 1), nn.ELU())\n",
    "\n",
    "        #self.n_cluster = n_cluster                \n",
    "        #self.cluster = nn.Sequential(nn.Linear(int((input_size - len(edge_features))/2), hidden_size*2), nn.ELU(), nn.Linear(hidden_size*2, 2*n_cluster))\n",
    "        #self.actual_cluster = nn.Linear(2*n_cluster, n_cluster)\n",
    "        #self.cos = nn.CosineSimilarity(dim=1)        \n",
    "        #self.dist = nn.PairwiseDistance()\n",
    "        #self.gnn_transform = nn.Sequential(nn.Linear(self.representataion_size, hidden_size), nn.ReLU(), nn.Dropout(drop_out))\n",
    "        self.counter = 0\n",
    "\n",
    "        self.objective = 'link_prediction'\n",
    "    def forward(self, z, edge_index, sigmoid = True):\n",
    "        if self.features_size > 0:\n",
    "            if self.objective == 'link_prediction':\n",
    "                edge_index_np = edge_index.cpu().numpy()\n",
    "                val_indices = x_edge_np[edge_index_np[0, :], edge_index_np[1, :]]\n",
    "                val_indices = np.squeeze(np.asarray(val_indices))\n",
    "                vals = x_edge_vals2[val_indices, :]\n",
    "            elif self.objective == 'sequence_prediction':\n",
    "                vals = torch.zeros((edge_index.shape[1], self.features_size)).to(dev)\n",
    "\n",
    "\n",
    "            features = self.feature_encoder(vals.to(dev), dev)\n",
    "            #features = vals.to(dev)\n",
    "            h1 = z[edge_index[0, :]]\n",
    "            h2 = z[edge_index[1, :]]\n",
    "\n",
    "            self.counter += 1\n",
    "\n",
    "            #rep = self.gnn_transform(torch.cat((h1, h2), dim=1))\n",
    "            res = self.transfer(torch.cat((self.cluster(h1), self.cluster(h2), features), dim=1))\n",
    "            #res = self.transfer(features)\n",
    "        else:\n",
    "            h1 = z[edge_index[0, :]]\n",
    "            h2 = z[edge_index[1, :]]\n",
    "\n",
    "            \n",
    "            res = self.transfer(torch.cat((h1, h2), dim=-1))\n",
    "\n",
    "            #res = self.transfer(torch.cat((self.cluster(h1), self.cluster(h2)), dim=1))\n",
    "            #res = torch.sum(torch.pow(F.softmax(self.cluster(h1)/1, dim=1) - F.softmax(self.cluster(h2)/1, dim=1), 2), dim=1)\n",
    "            #res = self.cos(self.cluster(h1), self.cluster(h2))\n",
    "            #res = - self.dist(self.cluster(h1), self.cluster(h2))\n",
    "            #print(res)\n",
    "        res = torch.sigmoid(res) if sigmoid else res\n",
    "        return res\n",
    "\n",
    "    def set_objective(self, objective):\n",
    "        self.objective = objective\n",
    "        \n",
    "    def clustering_loss(self, z, nodes, adjacency):\n",
    "        s = self.actual_cluster(torch.relu(self.cluster(z[nodes])))\n",
    "        s = torch.softmax(s, dim=-1)\n",
    "        entropy_loss = (-s * torch.log(s + EPS)).sum(dim=-1).mean()\n",
    "\n",
    "        ss = torch.matmul(s.transpose(0, 1), s)\n",
    "        i_s = torch.eye(self.n_cluster).type_as(ss)\n",
    "        ortho_loss = torch.norm(\n",
    "            ss / torch.norm(ss, dim=(-1, -2), keepdim=True) -\n",
    "            i_s / torch.norm(i_s), dim=(-1, -2))\n",
    "        ortho_loss = torch.mean(ortho_loss)\n",
    "\n",
    "        adjacency = adjacency.to(dev).float()\n",
    "        out_adj = torch.matmul(s.transpose(0, 1),torch.sparse.mm(adjacency, s))\n",
    "        # MinCUT regularization.\n",
    "        mincut_num = torch.trace(out_adj)\n",
    "        #d_flat = torch.einsum('ij->i', adjacency) # FIXME since I don't consider the whole adjacency matrix this could be a source of problem\n",
    "        d_flat = torch.sparse.sum(adjacency, dim=1).to_dense()\n",
    "        d = _diag(d_flat)\n",
    "        mincut_den = torch.trace(\n",
    "            torch.matmul(torch.matmul(s.transpose(0, 1), d), s))\n",
    "        mincut_loss = -(mincut_num / mincut_den)\n",
    "        mincut_loss = torch.mean(mincut_loss)\n",
    "\n",
    "        return ortho_loss, mincut_loss, entropy_loss\n",
    "    \n",
    "    def get_alignments(self, z, edge_index):\n",
    "        h1 = z[edge_index[0, :]]\n",
    "        h2 = z[edge_index[1, :]]\n",
    "        \n",
    "        h1 = torch.softmax(self.cluster(h1), dim=1)\n",
    "        h2 = torch.softmax(self.cluster(h2), dim=1)\n",
    "\n",
    "        h1_max = torch.argmax(h1, dim=1)\n",
    "        h2_max = torch.argmax(h2, dim=1)\n",
    "\n",
    "        h1_cluster = torch.zeros(*h1.shape)\n",
    "        h2_cluster = torch.zeros(*h2.shape)\n",
    "\n",
    "        h1_cluster[range(h1.size(0)), h1_max] = 1\n",
    "        h2_cluster[range(h2.size(0)), h2_max] = 1\n",
    "        res = torch.max(h1_cluster * h2_cluster, dim=1).values\n",
    "\n",
    "        #res = h1 * h2\n",
    "        #res = torch.sum(res, dim = 1)\n",
    "        return torch.unsqueeze(res, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(afeatures)\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features, n_head = 2, edge_feature_dim = 0,):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.GATConv(in_channels, 2*out_channels, heads= n_head)\n",
    "        self.conv2 = pyg_nn.GATConv(2 * n_head *  out_channels , out_channels, heads= 1)\n",
    "        self.fin_lin = nn.Linear(out_channels, out_channels)\n",
    "        \n",
    "\n",
    "        self.feature_encoder = afeatures.FeatureEncoding(features, [normalized_tag_frequencies, word_vectors])\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.feature_encoder(x, dev)\n",
    "        x = F.elu(self.conv1(x, edge_index, ))\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        return F.relu(self.fin_lin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_encoders_embedding(encoder):\n",
    "    for i,ft in enumerate(encoder.feature_types):\n",
    "        if ft.type == MAPPING:\n",
    "            print('doing it')\n",
    "            encoder.layers[i] = afeatures.MappingEncoding(encoder.layers[i].emb.weight, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "class DataEncoder():\n",
    "\n",
    "    def __init__(self, data_loader, model):\n",
    "        self.data_loader = data_loader\n",
    "        self.model = model\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i,batch in enumerate(tqdm(self.data_loader)):\n",
    "            \n",
    "            x = batch['x'][0].to(dev)\n",
    "            edge_index = batch['edge_index'][0].to(dev)\n",
    "            verse = batch['verse'][0]\n",
    "\n",
    "            if verse in masked_verses:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                if mask_language:\n",
    "                    x[:, 0] = 0\n",
    "                z = self.model.encode(x, edge_index)\n",
    "                \n",
    "            except Exception as e:\n",
    "                global sag, khar, gav\n",
    "                sag, khar, gav =  (i, batch, verse)\n",
    "                print(e)\n",
    "                1/0\n",
    "            \n",
    "            yield z, verse, i, batch\n",
    "\n",
    "def train(epoch, data_loader, max_batches=999999999):\n",
    "    global optimizer\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    data_encoder = DataEncoder(data_loader, model)\n",
    "\n",
    "    for z, verse, i, batch in data_encoder:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        target = batch['pos_classes'][0].to(dev)\n",
    "        _, labels = torch.max(target, 1)\n",
    "        \n",
    "        index = batch['pos_index'][0].to(dev)\n",
    "        preds = model.decoder(z, index)\n",
    "\n",
    "        loss = criterion(preds, labels)\n",
    "        loss = loss * target.shape[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 500 == 499:\n",
    "            print(f\"loss: {total_loss}\")\n",
    "            total_loss = 0\n",
    "            test(epoch, test_data_loader)\n",
    "            model.train()\n",
    "\n",
    "        if i == max_batches:\n",
    "            break\n",
    "    \n",
    "    print(f\"total train loss: {total_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_class, drop_out=0):\n",
    "        super(POSDecoder, self).__init__()\n",
    "\n",
    "        self.transfer = nn.Sequential(nn.Linear(input_size, hidden_size), nn.ReLU(), nn.Dropout(drop_out),\n",
    "                        nn.Linear(hidden_size, n_class))\n",
    "\n",
    "    def forward(self, z, index):\n",
    "        h = z[index, :]\n",
    "\n",
    "        res = self.transfer(h)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, testloader, filter_wordtypes=None):\n",
    "    print('testing',  epoch)\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    data_encoder = DataEncoder(testloader, model)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for z, verse, i, batch in data_encoder:\n",
    "            \n",
    "            target = batch['pos_classes'][0].to(dev)\n",
    "            index = batch['pos_index'][0].to(dev)\n",
    "            \n",
    "            if filter_wordtypes != None:\n",
    "                non_filtered_words = filter_wordtypes[batch['x'][0][:, 9].long()] == 1\n",
    "                non_filtered_words = non_filtered_words[index]\n",
    "                index = index[non_filtered_words]\n",
    "\n",
    "                target = target[non_filtered_words, :]\n",
    "\n",
    "            preds = model.decoder(z, index)\n",
    "            \n",
    "            if preds.size(0) > 0:\n",
    "                _, predicted = torch.max(preds, 1)\n",
    "                _, labels = torch.max(target, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'test, epoch: {epoch}, total:{total} ACC: {correct/total}')\n",
    "    clean_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(82.)\n",
      "tensor(30.0000)\n",
      "tensor(8.0000)\n",
      "tensor(3.0000)\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "print(wordtype_frequencies[736])\n",
    "print(wordtype_frequencies[1473])\n",
    "print(wordtype_frequencies[3683])\n",
    "print(wordtype_frequencies[7367])\n",
    "print(wordtype_frequencies[14733])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/250 [00:00<00:05, 44.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 65.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7482947706299318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frequent_words = torch.zeros(word_frequencies.size(0))\n",
    "frequent_words[word_frequencies > -1] = 1\n",
    "\n",
    "test(1, test_data_loader, filter_wordtypes=frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_verses = all_verses[:]\n",
    "test_verses = all_verses[:] \n",
    "editf1 = 'fin-x-bible-helfi'\n",
    "editf2 = \"heb-x-bible-helfi\"\n",
    "\n",
    "\n",
    "if 'jpn-x-bible-newworld' in  current_editions[:]:\n",
    "     current_editions.remove('jpn-x-bible-newworld')\n",
    "if 'grc-x-bible-unaccented' in  current_editions[:]:\n",
    "     current_editions.remove('grc-x-bible-unaccented')\n",
    "\n",
    "# train_dataset = torch.load(\"/mounts/work/ayyoob/models/gnn/dataset_helfi_train_community_word.pickle\", map_location=torch.device('cpu'))\n",
    "# #train_dataset, train_nodes_map = create_dataset(train_verses, verse_alignments_inter, small_editions)\n",
    "# features = train_dataset.features\n",
    "# train_nodes_map = train_dataset.nodes_map\n",
    "# #edge_index_intra_sent = train_dataset.edge_index_intra_sent\n",
    "# #test_edge_index_intra_sent = edge_index_intra_sent\n",
    "\n",
    "# # test_dataset, test_nodes_map = create_dataset(test_verses, verse_alignments_inter, small_editions)\n",
    "# test_dataset, test_nodes_map = train_dataset, train_nodes_map\n",
    "# test_verses = train_verses\n",
    "# print(train_dataset.x.shape)\n",
    "\n",
    "# # gutils.augment_features(test_dataset)\n",
    "# # x_edge, features_edge = gutils.create_edge_attribs(train_nodes_map, train_verses, small_editions, verse_alignments_inter, train_dataset.x.shape[0])\n",
    "# # with open(\"./dataset.pickle\", 'wb') as of:\n",
    "# #     pickle.dump(train_dataset, of)\n",
    "# gc.collect()\n",
    "\n",
    "data_dir_train = \"/mounts/data/proj/ayyoob/align_induction/dataset/dataset_helfi_train_community_word\"\n",
    "data_dir_blinker = \"/mounts/data/proj/ayyoob/align_induction/dataset/pruned_alignments_blinker_inter/\"\n",
    "data_dir_grc = \"/mounts/data/proj/ayyoob/align_induction/dataset/dataset_helfi_grc_community_word/\"\n",
    "data_dir_heb = \"/mounts/data/proj/ayyoob/align_induction/dataset/dataset_helfi_heb_community_word/\"\n",
    "\n",
    "train_dataset = torch.load(f\"{data_dir_train}/train_dataset_nox_noedge.torch.bin\")\n",
    "blinker_test_dataset = torch.load(f\"{data_dir_blinker}/train_dataset_nox_noedge.torch.bin\")\n",
    "grc_test_dataset = torch.load(f\"{data_dir_grc}/train_dataset_nox_noedge.torch.bin\")\n",
    "heb_test_dataset = torch.load(f\"{data_dir_heb}/train_dataset_nox_noedge.torch.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import collections\n",
    "\n",
    "postag_map = {\"ADJ\": 0, \"ADP\": 1, \"ADV\": 2, \"AUX\": 3, \"CCONJ\": 4, \"DET\": 5, \"INTJ\": 6, \"NOUN\": 7, \"NUM\": 8, \"PART\": 9, \"PRON\": 10, \"PROPN\": 11, \"PUNCT\": 12, \"SCONJ\": 13, \"SYM\": 14, \"VERB\": 15, \"X\": 16}\n",
    "\n",
    "pos_lang_list = [\"eng-x-bible-mixed\", \"deu-x-bible-newworld\", \"ces-x-bible-newworld\", \n",
    "\t\t\"fra-x-bible-louissegond\",\"hin-x-bible-newworld\", \"ita-x-bible-2009\", \n",
    "\t\t\"prs-x-bible-goodnews\", \"ron-x-bible-2006\", \"spa-x-bible-newworld\"]\n",
    "\n",
    "def get_db_nodecount(dataset):\n",
    "\tres = 0\n",
    "\tfor lang in dataset.nodes_map.values():\n",
    "\t\tfor verse in lang.values():\n",
    "\t\t\tres += len(verse)\n",
    "\t\n",
    "\treturn res\n",
    "\n",
    "def get_pos_tags(dataset, pos_lang_list):\n",
    "\tall_tags = {}\n",
    "\tfor lang in pos_lang_list:\n",
    "\t\tif lang not in dataset.nodes_map:\n",
    "\t\t\tcontinue\n",
    "\t\tall_tags[lang] = {}\n",
    "\t\twith codecs.open(F\"/mounts/work/mjalili/projects/gnn-align/data/pbc_pos_tags/{lang}.conllu\", \"r\", \"utf-8\") as lang_pos:\n",
    "\t\t\ttag_sent = []\n",
    "\t\t\tsent_id = \"\"\n",
    "\t\t\tfor sline in lang_pos:\n",
    "\t\t\t\tsline = sline.strip()\n",
    "\t\t\t\tif sline == \"\":\n",
    "\t\t\t\t\tif sent_id not in dataset.nodes_map[lang]:\n",
    "\t\t\t\t\t\ttag_sent = []\n",
    "\t\t\t\t\t\tsent_id = \"\"\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tall_tags[lang][sent_id] = [p[3] for p in tag_sent]\n",
    "\t\t\t\t\ttag_sent = []\n",
    "\t\t\t\t\tsent_id = \"\"\n",
    "\t\t\t\telif \"# verse_id\" in sline:\n",
    "\t\t\t\t\tsent_id = sline.split()[-1]\n",
    "\t\t\t\telif sline[0] == \"#\":\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttag_sent.append(sline.split(\"\\t\"))\n",
    "\n",
    "\tnode_count = get_db_nodecount(dataset)\n",
    "\tpos_labels = torch.zeros(node_count, len(postag_map))\n",
    "\tpos_node_cover = collections.defaultdict(list)\n",
    "\n",
    "\tfor lang in all_tags:\n",
    "\t\tfor sent_id in all_tags[lang]:\n",
    "\t\t\tsent_tags = all_tags[lang][sent_id]\n",
    "\t\t\tfor w_i in range(len(sent_tags)):\n",
    "\t\t\t\tif w_i not in dataset.nodes_map[lang][sent_id]:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tpos_labels[dataset.nodes_map[lang][sent_id][w_i], postag_map[sent_tags[w_i]]] = 1\n",
    "\t\t\t\tpos_node_cover[sent_id].append(dataset.nodes_map[lang][sent_id][w_i])\n",
    "\n",
    "\treturn pos_labels, pos_node_cover\n",
    "\t#pos_pickle = {\"pos_labels\": pos_labels, \"node_ids_train\": pos_ids_train, \"node_ids_dev\": pos_ids_dev}\n",
    "\t#torch.save(pos_pickle, '/mounts/work/ayyoob/models/gnn/postag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 14:34:45,779 - analytics - INFO - done reading alignments\n",
      "2021-11-03 14:34:45,780 - analytics - INFO - done saving pruned alignments\n"
     ]
    }
   ],
   "source": [
    "# blinker_test_dataset = torch.load(\"/mounts/work/ayyoob/models/gnn/dataset_blinker_full_community_word.pickle\", map_location=torch.device('cpu'))\n",
    "editf12 = \"eng-x-bible-mixed\"\n",
    "editf22 = 'fra-x-bible-louissegond'\n",
    "\n",
    "test_gold_eng_fra = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/eng_fra_pbc/eng-fra.gold\"\n",
    "\n",
    "pros_blinker, surs_blinker = autils.load_gold(test_gold_eng_fra)\n",
    "\n",
    "blinker_verse_alignments_inter = {}\n",
    "#blinker_verse_alignments_gdfa = {}\n",
    "#args = []\n",
    "#for i,verse in enumerate(blinker_verses):\n",
    "#    args.append((verse, current_editions))\n",
    "\n",
    "#with Pool(20) as p:\n",
    "#    all_res = p.map(get_pruned_verse_alignments, args)\n",
    "\n",
    "#for i,verse in enumerate(blinker_verses):\n",
    "#    verse_aligns_inter, verse_aligns_gdfa = all_res[i]\n",
    "\n",
    "#    blinker_verse_alignments_inter[verse] = verse_aligns_inter\n",
    "#    blinker_verse_alignments_gdfa[verse] = verse_aligns_gdfa\n",
    "\n",
    "utils.LOG.info(\"done reading alignments\")\n",
    "#torch.save(blinker_verse_alignments_inter, \"/mounts/work/ayyoob/models/gnn/pruned_alignments_blinker_inter.pickle\")\n",
    "#torch.save(blinker_verse_alignments_gdfa, \"/mounts/work/ayyoob/models/gnn/pruned_alignments_blinker_gdfa.pickle\")\n",
    "utils.LOG.info('done saving pruned alignments')\n",
    "\n",
    "#print('reading inter verse alignments')\n",
    "#blinker_verse_alignments_inter = torch.load(\"/mounts/work/ayyoob/models/gnn/pruned_alignments_blinker_inter.pickle\")\n",
    "#blinker_verse_alignments_gdfa = torch.load(\"/mounts/work/ayyoob/models/gnn/pruned_alignments_blinker_gdfa.pickle\")\n",
    "#gc.collect()\n",
    "#print('done reading inter verse alignments')\n",
    "\n",
    "verses_map = {}\n",
    "\n",
    "for edit in blinker_test_dataset.nodes_map:\n",
    "    for verse in blinker_test_dataset.nodes_map[edit]:\n",
    "        if verse not in verses_map:\n",
    "            for tok in blinker_test_dataset.nodes_map[edit][verse]:\n",
    "                verses_map[verse] = blinker_test_dataset.nodes_map[edit][verse][tok]\n",
    "                break\n",
    "\n",
    "sorted_verses = sorted(verses_map.items(), key = lambda x: x[1])\n",
    "blinker_verses = [item[0] for item in sorted_verses]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 14:34:46,144 - analytics - INFO - done reading alignments\n",
      "2021-11-03 14:34:46,146 - analytics - INFO - done saving pruned alignments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading inter verse alignments\n",
      "done reading inter verse alignments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importlib.reload(afeatures)\n",
    "#grc_test_dataset = torch.load(\"/mounts/work/ayyoob/models/gnn/dataset_helfi_grc_test_community_word.pickle\", map_location=torch.device('cpu'))\n",
    "editf_fin = \"fin-x-bible-helfi\"\n",
    "editf_grc = 'grc-x-bible-helfi'\n",
    "\n",
    "test_gold_grc = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi-fin-grc-gold-alignments_test.txt\"\n",
    "\n",
    "pros_grc, surs_grc = autils.load_gold(test_gold_grc)\n",
    "\n",
    "grc_test_verse_alignments_inter = {}\n",
    "grc_test_verse_alignments_gdfa = {}\n",
    "gc.collect()\n",
    "#args = []\n",
    "#for i,verse in enumerate(grc_verses):\n",
    "#    args.append((verse, current_editions))\n",
    "\n",
    "#with Pool(20) as p:\n",
    "#    all_res = p.map(get_pruned_verse_alignments, args)\n",
    "\n",
    "#for i,verse in enumerate(grc_verses):\n",
    "#    verse_aligns_inter, verse_aligns_gdfa = all_res[i]\n",
    "\n",
    "#    grc_test_verse_alignments_inter[verse] = verse_aligns_inter\n",
    "#    grc_test_verse_alignments_gdfa[verse] = verse_aligns_gdfa\n",
    "\n",
    "utils.LOG.info(\"done reading alignments\")\n",
    "#torch.save(grc_test_verse_alignments_inter, \"/mounts/work/ayyoob/models/gnn/pruned_alignments_grc_inter.pickle\")\n",
    "#torch.save(grc_test_verse_alignments_gdfa, \"/mounts/work/ayyoob/models/gnn/pruned_alignments_grc_gdfa.pickle\")\n",
    "utils.LOG.info('done saving pruned alignments')\n",
    "\n",
    "print('reading inter verse alignments')\n",
    "#grc_test_verse_alignments_inter = torch.load(\"/mounts/work/ayyoob/models/gnn/pruned_alignments_grc_inter.pickle\")\n",
    "#grc_test_verse_alignments_gdfa = torch.load(\"/mounts/work/ayyoob/models/gnn/pruned_alignments_grc_gdfa.pickle\")\n",
    "gc.collect()\n",
    "print('done reading inter verse alignments')\n",
    "\n",
    "verses_map = {}\n",
    "\n",
    "for edit in grc_test_dataset.nodes_map:\n",
    "    for verse in grc_test_dataset.nodes_map[edit]:\n",
    "        if verse not in verses_map:\n",
    "            for tok in grc_test_dataset.nodes_map[edit][verse]:\n",
    "                verses_map[verse] = grc_test_dataset.nodes_map[edit][verse][tok]\n",
    "                break\n",
    "\n",
    "sorted_verses = sorted(verses_map.items(), key = lambda x: x[1])\n",
    "grc_test_verses = [item[0] for item in sorted_verses]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading inter verse alignments\n",
      "done reading inter verse alignments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#heb_test_dataset = torch.load(\"/mounts/work/ayyoob/models/gnn/dataset_helfi_heb_test_community_word.pickle\", map_location=torch.device('cpu'))\n",
    "\n",
    "test_gold_heb = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi-fin-heb-gold-alignments_test.txt\"\n",
    "\n",
    "pros_heb, surs_heb = autils.load_gold(test_gold_heb)\n",
    "\n",
    "heb_test_verse_alignments_inter = {}\n",
    "heb_test_verse_alignments_gdfa = {}\n",
    "#args = []\n",
    "#for i,verse in enumerate(heb_verses):\n",
    "#    args.append((verse, current_editions))\n",
    "\n",
    "#with Pool(20) as p:\n",
    "#    all_res = p.map(get_pruned_verse_alignments, args)\n",
    "\n",
    "#for i,verse in enumerate(heb_verses):\n",
    "#    verse_aligns_inter, verse_aligns_gdfa = all_res[i]\n",
    "\n",
    "#    heb_test_verse_alignments_inter[verse] = verse_aligns_inter\n",
    "#    heb_test_verse_alignments_gdfa[verse] = verse_aligns_gdfa\n",
    "\n",
    "#utils.LOG.info(\"done reading alignments\")\n",
    "#torch.save(heb_test_verse_alignments_inter, \"/mounts/work/ayyoob/models/gnn/pruned_alignments_heb_inter.pickle\")\n",
    "#torch.save(heb_test_verse_alignments_gdfa, \"/mounts/work/ayyoob/models/gnn/pruned_alignments_heb_gdfa.pickle\")\n",
    "#utils.LOG.info('done saving pruned alignments')\n",
    "\n",
    "print('reading inter verse alignments')\n",
    "#heb_test_verse_alignments_inter = torch.load(\"/mounts/work/ayyoob/models/gnn/pruned_alignments_heb_inter.pickle\")\n",
    "#heb_test_verse_alignments_gdfa = torch.load(\"/mounts/work/ayyoob/models/gnn/pruned_alignments_heb_gdfa.pickle\")\n",
    "gc.collect()\n",
    "print('done reading inter verse alignments')\n",
    "\n",
    "verses_map = {}\n",
    "\n",
    "for edit in heb_test_dataset.nodes_map:\n",
    "    for verse in heb_test_dataset.nodes_map[edit]:\n",
    "        if verse not in verses_map:\n",
    "            for tok in heb_test_dataset.nodes_map[edit][verse]:\n",
    "                verses_map[verse] = heb_test_dataset.nodes_map[edit][verse][tok]\n",
    "                break\n",
    "\n",
    "sorted_verses = sorted(verses_map.items(), key = lambda x: x[1])\n",
    "heb_test_verses = [item[0] for item in sorted_verses]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "verses_map = {}\n",
    "\n",
    "for edit in train_dataset.nodes_map:\n",
    "    for verse in train_dataset.nodes_map[edit]:\n",
    "        if verse not in verses_map:\n",
    "            for tok in train_dataset.nodes_map[edit][verse]:\n",
    "                verses_map[verse] = train_dataset.nodes_map[edit][verse][tok]\n",
    "                break\n",
    "\n",
    "sorted_verses = sorted(verses_map.items(), key = lambda x: x[1])\n",
    "all_verses = [item[0] for item in sorted_verses]\n",
    "\n",
    "long_verses = set()\n",
    "\n",
    "for edit in train_dataset.nodes_map.keys():\n",
    "    for verse in train_dataset.nodes_map[edit]:\n",
    "        to_print = False\n",
    "        for tok in train_dataset.nodes_map[edit][verse]:\n",
    "            if tok > 150:\n",
    "                to_print = True\n",
    "        if to_print == True:\n",
    "            long_verses.add(verse)\n",
    "\n",
    "\n",
    "train_verses = all_verses[:]\n",
    "\n",
    "masked_verses = list(long_verses)\n",
    "#masked_verses.extend(blinker_verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "class POSTAGGNNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, verses, edit_files, alignments, node_cover, pos_labels, data_dir, create_data=False, group_size = 20):\n",
    "\n",
    "        self.pos_labels = pos_labels\n",
    "        self.data_dir = data_dir\n",
    "        self.items = self.calculate_size(verses, group_size, node_cover)\n",
    "\n",
    "        if create_data:\n",
    "            self.calculate_verse_stats(verses, edit_files, alignments, dataset, data_dir)            \n",
    "        \n",
    "    def calculate_size(self, verses, group_size, covered_verses):\n",
    "        res = []\n",
    "        for verse in verses:\n",
    "            covered_nodes = covered_verses[verse]\n",
    "            random.shuffle(covered_nodes)\n",
    "            items = [covered_nodes[i:i + group_size] for i in range(0, len(covered_nodes), group_size)]\n",
    "            res.extend([(verse, i) for i in items])\n",
    "\n",
    "        return res\n",
    "\n",
    "    def calculate_verse_stats(self,verses, edition_files, alignments, dataset, data_dir):\n",
    "\n",
    "        min_edge = 0\n",
    "        for verse in tqdm(verses):\n",
    "            min_nodes = 99999999999999\n",
    "            max_nodes = 0\n",
    "            edges_tmp = [[],[]]\n",
    "            x_tmp = []\n",
    "            features = []\n",
    "            for i,editf1 in enumerate(edition_files):\n",
    "                for j,editf2 in enumerate(edition_files[i+1:]):\n",
    "                    aligns = autils.get_aligns(editf1, editf2, alignments[verse])\n",
    "                    if aligns != None:\n",
    "                        for align in aligns:\n",
    "                            try:\n",
    "                                n1,_ = gutils.node_nom(verse, editf1, align[0], None, dataset.nodes_map, x_tmp, edition_files, features)\n",
    "                                n2,_ = gutils.node_nom(verse, editf2, align[1], None, dataset.nodes_map, x_tmp, edition_files, features)\n",
    "                                edges_tmp[0].extend([n1, n2])\n",
    "\n",
    "                                max_nodes = max(n1, n2, max_nodes)\n",
    "                                min_nodes = min(n1, n2, min_nodes)\n",
    "                            except Exception as e:\n",
    "                                print(editf1, editf2, verse)\n",
    "                                raise(e)\n",
    "\n",
    "            self.verse_info = {}\n",
    "\n",
    "            self.verse_info['padding'] = min_nodes\n",
    "            \n",
    "            self.verse_info['x'] = torch.clone(dataset.x[min_nodes:max_nodes+1,:])\n",
    "            \n",
    "            self.verse_info['edge_index'] = torch.clone(dataset.edge_index[:, min_edge : min_edge + len(edges_tmp[0])] - min_nodes)\n",
    "\n",
    "            if torch.min(self.verse_info['edge_index']) != 0:\n",
    "                print(verse, min_nodes, max_nodes, min_edge, len(edges_tmp[0]))\n",
    "                print(torch.min(self.verse_info['edge_index']))\n",
    "            \n",
    "            if self.verse_info['x'].shape[0] != torch.max(self.verse_info['edge_index']) + 1 :\n",
    "                print(verse, min_nodes, max_nodes, min_edge, len(edges_tmp[0]))\n",
    "                print(torch.min(self.verse_info['edge_index']))\n",
    "            \n",
    "            min_edge = min_edge + len(edges_tmp[0])\n",
    "\n",
    "            torch.save(self.verse_info, f\"{data_dir}/verses/{verse}_info.torch.bin\")\n",
    "        \n",
    "        dataset.x = None\n",
    "        dataset.edge_index = None\n",
    "        torch.save(dataset, f\"{data_dir}/train_dataset_nox_noedge.torch.bin\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        verse, nodes = self.items[idx]\n",
    "        \n",
    "        self.verse_info = {verse: torch.load(f'{self.data_dir}/verses/{verse}_info.torch.bin')}\n",
    "\n",
    "        word_number = self.verse_info[verse]['x'][:, 9]\n",
    "        word_number = torch.unsqueeze(word_number, 1)\n",
    "        self.verse_info[verse]['x'] = torch.cat((self.verse_info[verse]['x'], word_number), dim=1)\n",
    "        \n",
    "        return {'verse':verse, 'x':self.verse_info[verse]['x'], 'edge_index':self.verse_info[verse]['edge_index'], \n",
    "                'pos_classes': self.pos_labels[nodes, :], 'pos_index': torch.LongTensor(nodes) - self.verse_info[verse]['padding']}\n",
    "\n",
    "\n",
    "# train_pos_labels, train_pos_node_cover = get_pos_tags(train_dataset, pos_lang_list)\n",
    "# torch.save({'pos_labels':train_pos_labels, 'pos_node_cover':train_pos_node_cover}, f'{data_dir_train}/pos_data.torch.bin')\n",
    "pos_data = torch.load(f'{data_dir_train}/pos_data.torch.bin')\n",
    "train_pos_labels, train_pos_node_cover = pos_data['pos_labels'], pos_data['pos_node_cover']\n",
    "gnn_dataset_train_pos = POSTAGGNNDataset(train_dataset, train_verses, current_editions, verse_alignments_inter,\n",
    "                       train_pos_node_cover, train_pos_labels, data_dir_train, group_size = 100)\n",
    "\n",
    "# blinker_pos_labels, blinker_pos_node_cover = get_pos_tags(blinker_test_dataset, pos_lang_list)\n",
    "# torch.save({'pos_labels':blinker_pos_labels, 'pos_node_cover': blinker_pos_node_cover}, f'{data_dir_blinker}/pos_data.torch.bin')\n",
    "pos_data = torch.load(f'{data_dir_blinker}/pos_data.torch.bin')\n",
    "blinker_pos_labels, blinker_pos_node_cover = pos_data['pos_labels'], pos_data['pos_node_cover']\n",
    "gnn_dataset_blinker_pos = POSTAGGNNDataset(blinker_test_dataset, blinker_verses, current_editions, blinker_verse_alignments_inter,\n",
    "                             blinker_pos_node_cover, blinker_pos_labels, data_dir_blinker, group_size = 100)\n",
    "\n",
    "#grc_pos_labels, grc_pos_node_cover = get_pos_tags(grc_test_dataset)\n",
    "#torch.save({'pos_labels':grc_pos_labels, 'pos_node_cover': grc_pos_node_cover}, f'{data_dir_grc}/pos_data.torch.bin')\n",
    "pos_data = torch.load(f'{data_dir_grc}/pos_data.torch.bin')\n",
    "grc_pos_labels, grc_pos_node_cover = pos_data['pos_labels'], pos_data['pos_node_cover']\n",
    "gnn_dataset_grc_pos = POSTAGGNNDataset(grc_test_dataset, grc_test_verses, current_editions, grc_test_verse_alignments_inter,\n",
    "                            grc_pos_node_cover, grc_pos_labels, data_dir_grc, group_size = 10000)\n",
    "\n",
    "#heb_pos_labels, heb_pos_node_cover = get_pos_tags(heb_test_dataset)\n",
    "#torch.save({'pos_labels':heb_pos_labels, 'pos_node_cover': heb_pos_node_cover}, f'{data_dir_heb}/pos_data.torch.bin')\n",
    "pos_data = torch.load(f'{data_dir_heb}/pos_data.torch.bin')\n",
    "heb_pos_labels, heb_pos_node_cover = pos_data['pos_labels'], pos_data['pos_node_cover']\n",
    "gnn_dataset_heb_pos = POSTAGGNNDataset(heb_test_dataset, heb_test_verses, current_editions, heb_test_verse_alignments_inter,\n",
    "                            heb_pos_node_cover, heb_pos_labels, data_dir_heb, group_size = 10000)\n",
    "\n",
    "print(len(gnn_dataset_train_pos))\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_eng_langs = pos_lang_list[:]\n",
    "no_eng_langs.remove('eng-x-bible-mixed')\n",
    "\n",
    "train_pos_labels, train_pos_node_cover = get_pos_tags(train_dataset, no_eng_langs)\n",
    "gnn_dataset_train_pos = POSTAGGNNDataset(train_dataset, train_verses, current_editions, verse_alignments_inter,\n",
    "                       train_pos_node_cover, train_pos_labels, data_dir_train, group_size = 100)\n",
    "\n",
    "blinker_pos_labels, blinker_pos_node_cover = get_pos_tags(blinker_test_dataset, ['eng-x-bible-mixed'])\n",
    "gnn_dataset_blinker_pos = POSTAGGNNDataset(blinker_test_dataset, blinker_verses, current_editions, blinker_verse_alignments_inter,\n",
    "                             blinker_pos_node_cover, blinker_pos_labels, data_dir_blinker, group_size = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    model.encoder.feature_encoder.feature_types[0] = afeatures.OneHotFeature(20, 83, 'editf')\n",
    "    model.encoder.feature_encoder.feature_types[1] = afeatures.OneHotFeature(32, 150, 'position')\n",
    "    model.encoder.feature_encoder.feature_types[2] = afeatures.FloatFeature(4, 'degree_centrality')\n",
    "    model.encoder.feature_encoder.feature_types[3] = afeatures.FloatFeature(4, 'closeness_centrality')\n",
    "    model.encoder.feature_encoder.feature_types[4] = afeatures.FloatFeature(4, 'betweenness_centrality')\n",
    "    model.encoder.feature_encoder.feature_types[5] = afeatures.FloatFeature(4, 'load_centrality')\n",
    "    model.encoder.feature_encoder.feature_types[6] = afeatures.FloatFeature(4, 'harmonic_centrality')\n",
    "    model.encoder.feature_encoder.feature_types[7] = afeatures.OneHotFeature(32, 250, 'greedy_modularity_community')\n",
    "    model.encoder.feature_encoder.feature_types[8] = afeatures.OneHotFeature(32, 250, 'community_2')\n",
    "    model.encoder.feature_encoder.feature_types[9] = afeatures.MappingFeature(100, 'word')\n",
    "    torch.save(model, f'/mounts/work/ayyoob/models/gnn/checkpoint/postagging/pos_tagging_{name}_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(1, test_data_loader) \n",
    "\n",
    "#finetune_pos_labels, finetune_pos_node_cover = get_pos_tags(train_dataset, ['eng-x-bible-mixed'])\n",
    "#gnn_dataset_finetune_pos = POSTAGGNNDataset(train_dataset, train_verses, current_editions, verse_alignments_inter,\n",
    "#                       finetune_pos_node_cover, finetune_pos_labels, data_dir_train, group_size = 100)\n",
    "#finetune_data_loader = DataLoader(gnn_dataset_finetune_pos, batch_size=1, shuffle=False)\n",
    "\n",
    "# train(1, finetune_data_loader, max_batches=1000)\n",
    "# test(1, test_data_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50092 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing it\n",
      "model params - decoder params - conv1 237075569 542737\n",
      "\n",
      "----------------epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 497/50092 [00:44<45:41, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 48799.44767956436\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 16.09it/s]\n",
      "  1%|          | 502/50092 [01:01<20:11:44,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7156613615086265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 999/50092 [01:32<53:00, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 41196.18838374689\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 73.57it/s]\n",
      "  2%|▏         | 1001/50092 [01:36<8:52:57,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7278320181891133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1499/50092 [02:07<45:49, 17.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 39769.12810832262\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 80.14it/s] \n",
      "  3%|▎         | 1501/50092 [02:11<7:19:54,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7264945833890598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1999/50092 [02:37<42:11, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 37065.37112350017\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.52it/s]\n",
      "  4%|▍         | 2003/50092 [02:40<3:39:57,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7317105791092684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2498/50092 [03:08<45:36, 17.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 37646.55064421892\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 75.28it/s]\n",
      "  5%|▍         | 2502/50092 [03:12<5:39:40,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7165975658686639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2998/50092 [03:42<56:43, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35238.82750111818\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.86it/s]\n",
      "  6%|▌         | 3002/50092 [03:47<6:27:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7410726227096429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3498/50092 [04:16<40:56, 18.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 36328.86516368389\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 125.58it/s]\n",
      "  7%|▋         | 3502/50092 [04:18<3:34:05,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7272970442690919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3998/50092 [04:46<47:17, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35398.602401934564\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 75.52it/s]\n",
      "  8%|▊         | 4002/50092 [04:50<5:38:46,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.726227096429049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 4498/50092 [05:19<49:07, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33791.40695218742\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 66.56it/s]\n",
      "  9%|▉         | 4502/50092 [05:23<6:19:30,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7136552093085462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4998/50092 [05:53<39:59, 18.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33633.702343573794\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.95it/s]\n",
      " 10%|▉         | 5002/50092 [05:57<5:15:08,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.727698274709108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 5498/50092 [06:26<40:56, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34305.62544482574\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.93it/s]\n",
      " 11%|█         | 5502/50092 [06:30<5:01:09,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7343854487093754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5997/50092 [07:00<39:55, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34277.779251269996\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 77.28it/s]\n",
      " 12%|█▏        | 6000/50092 [07:04<5:53:44,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7337167313093487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 6498/50092 [07:31<34:15, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34190.42884071171\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 114.04it/s]\n",
      " 13%|█▎        | 6501/50092 [07:34<4:25:20,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7406713922696269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6999/50092 [08:00<41:41, 17.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35352.5726903528\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 113.48it/s]\n",
      " 14%|█▍        | 7001/50092 [08:03<4:16:02,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7319780660692792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 7498/50092 [08:31<46:19, 15.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32382.71587175876\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 78.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7494984619499799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 7999/50092 [09:04<41:04, 17.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32639.994661927223\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.55it/s]\n",
      " 16%|█▌        | 8001/50092 [09:08<7:43:43,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7480272836699211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8498/50092 [09:37<33:07, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34353.74801325798\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.24it/s]\n",
      " 17%|█▋        | 8503/50092 [09:41<4:12:16,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7494984619499799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 8999/50092 [10:09<40:18, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32671.059515953064\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 74.21it/s]\n",
      " 18%|█▊        | 9001/50092 [10:13<6:30:20,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7504346663100174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 9498/50092 [10:41<38:44, 17.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32700.503717336804\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 75.17it/s]\n",
      " 19%|█▉        | 9502/50092 [10:45<5:18:16,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7433462618697338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 9998/50092 [11:10<26:59, 24.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32989.85312036052\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 121.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7412063661896483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10497/50092 [11:38<31:16, 21.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32904.74915705621\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.33it/s]\n",
      " 21%|██        | 10503/50092 [11:41<2:31:43,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7535107663501405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 10999/50092 [12:06<32:07, 20.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33811.54283161275\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 115.95it/s]\n",
      " 22%|██▏       | 11002/50092 [12:08<3:29:16,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7381302661495253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11497/50092 [12:33<32:57, 19.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33730.43497843016\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 121.82it/s]\n",
      " 23%|██▎       | 11502/50092 [12:36<2:44:21,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7417413401096696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 11998/50092 [13:02<44:01, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32363.830291628838\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 122.54it/s]\n",
      " 24%|██▍       | 12004/50092 [13:05<2:43:39,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7279657616691186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 12498/50092 [13:35<31:13, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31031.426498265937\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 122.50it/s]\n",
      " 25%|██▍       | 12501/50092 [13:38<3:17:44,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7381302661495253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 12998/50092 [14:02<29:13, 21.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32194.849408335984\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 127.81it/s]\n",
      " 26%|██▌       | 13001/50092 [14:04<3:07:22,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7628728099505149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 13497/50092 [14:28<30:20, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33929.85216128826\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.14it/s]\n",
      " 27%|██▋       | 13502/50092 [14:31<2:31:39,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7456199010298248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 13998/50092 [14:54<25:49, 23.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32897.652436077595\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.93it/s]\n",
      " 28%|██▊       | 14003/50092 [14:57<2:16:41,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7524408185100976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 14498/50092 [15:21<28:03, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32619.744320064783\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.40it/s]\n",
      " 29%|██▉       | 14503/50092 [15:23<2:26:11,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7571218403102848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 14998/50092 [15:47<26:28, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33237.86549255252\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.12it/s]\n",
      " 30%|██▉       | 15003/50092 [15:50<2:20:43,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7501671793500067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 15499/50092 [16:13<24:51, 23.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33020.059806099074\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 125.05it/s]\n",
      " 31%|███       | 15502/50092 [16:16<2:48:39,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7624715795104988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 15999/50092 [16:39<27:20, 20.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32129.598574459553\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 122.56it/s]\n",
      " 32%|███▏      | 16002/50092 [16:41<2:49:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7454861575498194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 16498/50092 [17:05<26:20, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33053.440896987915\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 126.03it/s]\n",
      " 33%|███▎      | 16501/50092 [17:08<2:46:45,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7647452186705898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 16999/50092 [17:30<24:20, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32032.457145174965\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.98it/s]\n",
      " 34%|███▍      | 17002/50092 [17:33<2:44:15,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7480272836699211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 17498/50092 [17:55<25:34, 21.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31928.87159362994\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.07it/s]\n",
      " 35%|███▍      | 17504/50092 [17:58<1:53:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7446836966697874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 17998/50092 [18:20<25:01, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30422.138894965872\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.85it/s]\n",
      " 36%|███▌      | 18001/50092 [18:22<2:33:36,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7385314965895413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 18497/50092 [18:44<26:22, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30655.893465727568\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 118.49it/s]\n",
      " 37%|███▋      | 18503/50092 [18:47<2:01:17,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.752975792430119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 18996/50092 [19:10<24:09, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31371.049417626113\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 120.26it/s]\n",
      " 38%|███▊      | 19002/50092 [19:12<1:57:29,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7501671793500067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 19499/50092 [19:35<26:46, 19.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32101.68128547445\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 120.01it/s]\n",
      " 39%|███▉      | 19504/50092 [19:38<2:04:05,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7497659489099906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 19997/50092 [20:03<34:15, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33455.11598099768\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.21it/s]\n",
      " 40%|███▉      | 20002/50092 [20:05<2:21:57,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7632740403905309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 20497/50092 [20:29<20:15, 24.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32088.91382573545\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.75it/s]\n",
      " 41%|████      | 20502/50092 [20:32<1:53:39,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7536445098301457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 20997/50092 [20:54<20:28, 23.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32640.671494985\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 122.15it/s]\n",
      " 42%|████▏     | 21003/50092 [20:57<1:43:03,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, ACC: 0.7486960010699478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 21336/50092 [21:11<28:33, 16.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a5ab4a8db196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m        \u001b[0;31m#edge_index_seq_sent_neg = get_negative_edges_seq(train_dataset.nodes_map).to(dev)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m    \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m#   save_model(model, 'freeze-embedding_noLang')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m    \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-30c04d4ca67a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, data_loader, max_batches)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdata_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-30c04d4ca67a>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-b8f0f31979c1>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverse_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mverse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.data_dir}/verses/{verse}_info.torch.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mword_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverse_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mverse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;31m# If we want to actually tail call to torch.jit.load, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_is_zipfile\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mbyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mbyte\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mread_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "mask_language = True\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "features = train_dataset.features\n",
    "\n",
    "train_data_loader = DataLoader(gnn_dataset_train_pos, batch_size=1, shuffle=True)\n",
    "test_data_loader = DataLoader(gnn_dataset_blinker_pos, batch_size=1, shuffle=True)\n",
    "\n",
    "clean_memory()\n",
    "drop_out = 0\n",
    "n_head = 1\n",
    "\n",
    "channels = 512\n",
    "\n",
    "decoder_in_dim = n_head * channels \n",
    "decoder = POSDecoder(decoder_in_dim, decoder_in_dim*2, len(postag_map))\n",
    "model = torch.load('/mounts/work/ayyoob/models/gnn/checkpoint/gnn_512_flggll_word_halfTrain_nofeatlinear_encoderlineear_decoderonelayer20210910-235352-.pickle')\n",
    "freeze_encoders_embedding(model.encoder.feature_encoder)\n",
    "\n",
    "model.decoder = decoder\n",
    "model.to(dev)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "torch.set_printoptions(edgeitems=5)\n",
    "print(\"model params - decoder params - conv1\", sum(p.numel() for p in model.parameters()), sum(p.numel() for p in decoder.parameters()))\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "   print(f\"\\n----------------epoch {epoch} ---------------\")\n",
    "    \n",
    "   #if epoch % 1 == 0:\n",
    "   #    train_neg_edge_index = gutils.get_negative_edges(train_verses, small_editions, train_dataset.nodes_map,  verse_alignments_inter).to(dev)\n",
    "       #edge_index_seq_sent_neg = get_negative_edges_seq(train_dataset.nodes_map).to(dev)\n",
    "\n",
    "   train(epoch, train_data_loader)\n",
    "#   save_model(model, 'freeze-embedding_noLang')\n",
    "   test(epoch, test_data_loader) \n",
    "   clean_memory()\n",
    "\n",
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = sag\n",
    "#batch = khar\n",
    "#verse = gav\n",
    "#print(i, verse)\n",
    "\n",
    "#keys = list(gnn_dataset.verse_info.keys())\n",
    "\n",
    "#gnn_dataset.verse_info[verse]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/mounts/work/ayyoob/models/gnn/checkpoint/pos_tagging_zeta_1_20210915-011448.pickle')\n",
    "torch.cuda.set_device(4)\n",
    "model.to(dev)\n",
    "batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2354770, 100)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec.load(\"/mounts/work/ayyoob/models/w2v/word2vec_helfi_langs_15e.model\")\n",
    "\n",
    "print(w2v_model.wv.vectors.shape)\n",
    "word_vectors = torch.from_numpy(w2v_model.wv.vectors).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24078/24078 [08:30<00:00, 47.16it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_words_tag_frequence(model, word_count, class_count, data_loader, tag_frequencies=None, from_gold_data=False):\n",
    "    \n",
    "    res = tag_frequencies\n",
    "    if res == None:\n",
    "        res = torch.ones(word_count, class_count)\n",
    "        res[:, :] = 0.0000001\n",
    "    \n",
    "    \n",
    "    data_encoder = DataEncoder(data_loader, model)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for z, verse, i, batch in data_encoder:\n",
    "            index = batch['pos_index'][0].to(dev)\n",
    "            \n",
    "            if from_gold_data:\n",
    "                tags_onehot = batch['pos_classes'][0]\n",
    "            else:\n",
    "                tags_onehot = model.decoder(z, index)\n",
    "\n",
    "            max_values, pos_tags = torch.max(torch.softmax(tags_onehot, dim=1), 1)\n",
    "            word_pos = batch['x'][0][index, 9]\n",
    "\n",
    "            if not from_gold_data:\n",
    "                accepted_values = max_values > 0.5\n",
    "                word_pos = word_pos[accepted_values]\n",
    "                pos_tags = pos_tags[accepted_values]\n",
    "\n",
    "            res[word_pos.long(), pos_tags.long()] += 1\n",
    "    \n",
    "    sm = torch.sum(res, dim=1)\n",
    "    res_normalized = (res.transpose(1,0) / sm).transpose(1,0)\n",
    "    \n",
    "    return res_normalized, res\n",
    "\n",
    "#gnn_dataset_train_pos_bigbatch = POSTAGGNNDataset(train_dataset, train_verses, current_editions, verse_alignments_inter,\n",
    "#                    train_pos_node_cover, train_pos_labels, data_dir_train, group_size = 10000)\n",
    "#train_data_loader_bigbatch = DataLoader(gnn_dataset_train_pos_bigbatch, batch_size=1, shuffle=True)\n",
    "normalized_tag_frequencies, tag_frequencies_other = get_words_tag_frequence(model, 2354770, len(postag_map), train_data_loader_bigbatch, from_gold_data=True)\n",
    "\n",
    "#english_train_pos_labels, english_train_pos_node_cover = get_pos_tags(train_dataset,['eng-x-bible-mixed'])\n",
    "#gnn_dataset_english_pos = POSTAGGNNDataset(train_dataset, train_verses, current_editions, verse_alignments_inter,\n",
    "#                    english_train_pos_node_cover, english_train_pos_labels, data_dir_train, group_size = 500)\n",
    "#english_data_loader = DataLoader(gnn_dataset_english_pos, batch_size=1, shuffle=False)\n",
    "\n",
    "#normalized_tag_frequencies_english, tag_frequencies_english = get_words_tag_frequence(model, 2354770, len(postag_map), english_data_loader)\n",
    "\n",
    "tag_frequencies = tag_frequencies_other + tag_frequencies_english\n",
    "sm = torch.sum(tag_frequencies, dim=1)\n",
    "normalized_tag_frequencies = (tag_frequencies.transpose(1,0) / sm).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = torch.sum(tag_frequencies_english, dim=1)\n",
    "tag_frequencies_copy = tag_frequencies.detach().clone()\n",
    "\n",
    "tag_frequencies_copy[torch.logical_and(word_frequencies>0.1, word_frequencies<3), :] = 0.0000001\n",
    "\n",
    "uniform_noise = torch.BoolTensor(tag_frequencies.size(0))\n",
    "uniform_noise[:] = True\n",
    "shuffle_tensor = torch.randperm(tag_frequencies.size(0))[:int(tag_frequencies.size(0)*0.7)]\n",
    "uniform_noise[shuffle_tensor] = False\n",
    "tag_frequencies_copy[torch.logical_and(uniform_noise, word_frequencies < 0.1), :] = 0.0000001\n",
    "\n",
    "sm = torch.sum(tag_frequencies_copy, dim=1)\n",
    "normalized_tag_frequencies = (tag_frequencies_copy.transpose(1,0) / sm).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2354770])\n",
      "torch.Size([14734, 17])\n",
      "quarter size 7367\n",
      "general accuracy tensor(0.6985)\n",
      "first quarter accuracy tensor(0.7789)\n",
      "last part accuracy tensor(0.6182)\n",
      "total token count tensor(550089.)\n",
      "first quarter words token count tensor(280803.)\n",
      "1st frequency tensor(21465.)\n",
      "10st frequency tensor(5141.)\n",
      "100st frequency tensor(796.)\n",
      "100st frequency tensor(79.)\n",
      "1000st frequency tensor(51.)\n",
      "10000st frequency tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#normalized_gold_frequencies, gold_frequencies_all = get_words_tag_frequence(model, 2354770, len(postag_map), english_data_loader, from_gold_data=True)\n",
    "\n",
    "#gold_frequencies_all = gold_frequencies\n",
    "word_frequencies = torch.sum(gold_frequencies_all, dim=1)\n",
    "\n",
    "subjectword_indices =  word_frequencies > 0.1\n",
    "print(word_frequencies.shape)\n",
    "gold_frequencies = gold_frequencies_all[subjectword_indices, :]\n",
    "predicted_frequencies = tag_frequencies_english[subjectword_indices, :]\n",
    "wordtype_frequencies = word_frequencies[subjectword_indices]\n",
    "print(gold_frequencies.shape)\n",
    "\n",
    "_, gold_tags = torch.max(gold_frequencies, dim=1)\n",
    "_, predicted_tags = torch.max(predicted_frequencies, dim=1)\n",
    "\n",
    "sorted_wordtype_frequencies, sort_pattern = torch.sort(wordtype_frequencies, descending=True)\n",
    "\n",
    "sorted_gold_tags = gold_tags[sort_pattern]\n",
    "sorted_predicted_tags = predicted_tags[sort_pattern]\n",
    "quarter_size = int(sorted_gold_tags.size(0)/2.0)\n",
    "\n",
    "print('quarter size', quarter_size)\n",
    "print(\"general accuracy\", torch.sum(gold_tags == predicted_tags)/predicted_tags.size(0))\n",
    "print('first quarter accuracy', torch.sum(sorted_gold_tags[:quarter_size] == sorted_predicted_tags[:quarter_size])/quarter_size)\n",
    "print('last part accuracy', torch.sum(sorted_gold_tags[1*quarter_size:] == sorted_predicted_tags[1*quarter_size:])/sorted_predicted_tags[1*quarter_size:].size(0))\n",
    "\n",
    "print('total token count', torch.sum(wordtype_frequencies))\n",
    "print('first quarter words token count', torch.sum(word_frequencies[:quarter_size]))\n",
    "\n",
    "print('1st frequency', sorted_wordtype_frequencies[0])\n",
    "print('10st frequency', sorted_wordtype_frequencies[10])\n",
    "print('100st frequency', sorted_wordtype_frequencies[100])\n",
    "print('100st frequency', sorted_wordtype_frequencies[736])\n",
    "print('1000st frequency', sorted_wordtype_frequencies[1000])\n",
    "print('10000st frequency', sorted_wordtype_frequencies[10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<my_utils.alignment_features.MappingFeature at 0x7f3ed49bbe10>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.pop()\n",
    "#features.append(afeatures.MappingFeature(len(postag_map), 'tag_priors'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized_tag_frequencies = torch.softmax(tag_frequencies_copy, dim=1)\n",
    "\n",
    "sm = torch.sum(tag_frequencies_copy, dim=1)\n",
    "normalized_tag_frequencies = (tag_frequencies_copy.transpose(1,0) / sm).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/50092 [00:00<36:34, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing it\n",
      "doing it\n",
      "model params - decoder params - conv1 277124067 542737\n",
      "\n",
      "----------------epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 497/50092 [00:19<29:48, 27.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 50028.33756018989\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 69.40it/s]\n",
      "  1%|          | 503/50092 [00:24<4:33:43,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7607329142704293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 999/50092 [00:44<31:09, 26.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 37006.25385519862\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 68.74it/s]\n",
      "  2%|▏         | 1005/50092 [00:49<5:08:57,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7639427577905578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1499/50092 [01:08<33:34, 24.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32329.76092045009\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 72.19it/s]\n",
      "  3%|▎         | 1502/50092 [01:12<6:00:55,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7762471579510499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1997/50092 [01:32<29:15, 27.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31273.74161523208\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.16it/s]\n",
      "  4%|▍         | 2002/50092 [01:36<4:50:26,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7920288885916812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2496/50092 [01:57<28:26, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31825.705653997138\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.70it/s]\n",
      "  5%|▍         | 2503/50092 [02:01<3:50:03,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7699612143907985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2996/50092 [02:20<33:10, 23.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30975.299791529775\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 67.21it/s]\n",
      "  6%|▌         | 3003/50092 [02:25<4:06:15,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7523070750300923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3497/50092 [02:46<59:49, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30615.351738989353\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 68.04it/s]\n",
      "  7%|▋         | 3502/50092 [02:50<5:13:27,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7674200882706969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3998/50092 [03:11<31:35, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29452.621622942388\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.14it/s]\n",
      "  8%|▊         | 4004/50092 [03:16<4:06:45,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7894877624715795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 4497/50092 [03:38<33:13, 22.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28462.961360280402\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 65.48it/s]\n",
      "  9%|▉         | 4502/50092 [03:42<4:48:09,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7767821318710713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4997/50092 [04:04<29:00, 25.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28322.44477611035\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 66.72it/s]\n",
      " 10%|▉         | 5003/50092 [04:09<4:31:52,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7838705363113548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 5498/50092 [04:31<33:24, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27866.386859484017\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7781195666711248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5999/50092 [04:56<28:28, 25.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26280.94672359407\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 68.16it/s]\n",
      " 12%|█▏        | 6002/50092 [05:00<5:45:43,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.776648388391066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 6498/50092 [05:22<35:06, 20.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28455.01563628018\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.10it/s]\n",
      " 13%|█▎        | 6503/50092 [05:26<4:35:28,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.78774909723151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6998/50092 [05:47<31:12, 23.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27225.858451917768\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 68.62it/s]\n",
      " 14%|█▍        | 7001/50092 [05:52<5:41:53,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7856092015514243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 7498/50092 [06:13<32:51, 21.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28735.285573229194\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 69.83it/s]\n",
      " 15%|█▍        | 7504/50092 [06:18<3:58:01,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7674200882706969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 7999/50092 [06:39<38:27, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26986.185728102922\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 68.33it/s]\n",
      " 16%|█▌        | 8004/50092 [06:43<4:21:26,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7762471579510499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8498/50092 [07:05<26:00, 26.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27328.305964128114\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 69.58it/s]\n",
      " 17%|█▋        | 8504/50092 [07:09<3:41:17,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7692924969907717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 8998/50092 [07:30<27:21, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27048.401817161124\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.05it/s]\n",
      " 18%|█▊        | 9003/50092 [07:35<4:00:31,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.774775979670991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 9499/50092 [07:56<27:58, 24.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25823.01291858824\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.91it/s]\n",
      " 19%|█▉        | 9504/50092 [08:00<3:59:08,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.796174936471847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 9998/50092 [08:22<35:30, 18.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26209.95795180835\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.36it/s]\n",
      " 20%|█▉        | 10002/50092 [08:26<4:29:53,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7654139360706166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10497/50092 [08:47<27:29, 24.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26488.532769978046\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.10it/s]\n",
      " 21%|██        | 10503/50092 [08:52<3:40:54,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7832018189113281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 10998/50092 [09:13<27:31, 23.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26814.758522910997\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.32it/s]\n",
      " 22%|██▏       | 11003/50092 [09:18<3:56:41,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7719673665908787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11499/50092 [09:38<30:37, 21.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26724.291063766927\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 69.96it/s]\n",
      " 23%|██▎       | 11502/50092 [09:43<5:15:18,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7741072622709643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 11997/50092 [10:03<24:00, 26.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26256.39492763579\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.95it/s]\n",
      " 24%|██▍       | 12003/50092 [10:07<3:28:17,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.784672997191387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 12499/50092 [10:28<26:59, 23.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25824.002780228853\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.73it/s]\n",
      " 25%|██▍       | 12504/50092 [10:32<3:46:14,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7722348535508894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 12997/50092 [10:53<26:52, 23.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26077.71237328276\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 69.61it/s]\n",
      " 26%|██▌       | 13003/50092 [10:57<3:26:38,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7634077838705363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 13497/50092 [11:17<25:02, 24.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26766.769398599863\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.28it/s]\n",
      " 27%|██▋       | 13503/50092 [11:22<3:20:50,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7527083054701084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 13998/50092 [11:42<27:46, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26687.026797406375\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.34it/s]\n",
      " 28%|██▊       | 14004/50092 [11:46<3:20:15,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7834693058713388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 14499/50092 [12:07<24:11, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25657.395946461707\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.39it/s]\n",
      " 29%|██▉       | 14502/50092 [12:11<4:26:19,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7680888056707236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 14998/50092 [12:31<21:21, 27.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25580.057747807354\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.07it/s]\n",
      " 30%|██▉       | 15004/50092 [12:36<3:06:14,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7842717667513709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 15498/50092 [12:56<21:19, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26517.97972458601\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.78it/s]\n",
      " 31%|███       | 15503/50092 [13:01<3:26:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7869466363514779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 15997/50092 [13:22<27:46, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25689.592673654668\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.85it/s]\n",
      " 32%|███▏      | 16003/50092 [13:26<3:05:27,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7886853015915474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 16497/50092 [13:48<21:47, 25.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28110.38676771242\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.99it/s]\n",
      " 33%|███▎      | 16503/50092 [13:52<2:59:32,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7886853015915474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 16997/50092 [14:13<20:48, 26.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26594.587500136346\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:05<00:00, 44.68it/s]\n",
      " 34%|███▍      | 17003/50092 [14:20<4:07:39,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7805269493112211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 17498/50092 [14:43<21:28, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26259.69749303721\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 72.15it/s]\n",
      " 35%|███▍      | 17504/50092 [14:47<2:58:04,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7898889929115955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 17998/50092 [15:08<21:15, 25.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25970.097008548677\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 69.05it/s]\n",
      " 36%|███▌      | 18004/50092 [15:13<2:58:34,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7719673665908787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 18498/50092 [15:34<23:24, 22.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25864.933828270063\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 71.75it/s]\n",
      " 37%|███▋      | 18503/50092 [15:39<3:07:20,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7806606927912264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 18999/50092 [16:00<22:06, 23.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23919.57565147057\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 69.64it/s]\n",
      " 38%|███▊      | 19002/50092 [16:05<4:03:36,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7860104319914404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 19499/50092 [16:25<24:09, 21.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26361.21549139917\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 73.16it/s]\n",
      " 39%|███▉      | 19505/50092 [16:30<2:44:55,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7738397753109536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 19999/50092 [16:51<17:50, 28.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25651.105039205402\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 70.36it/s]\n",
      " 40%|███▉      | 20002/50092 [16:55<3:36:29,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7810619232312425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 20496/50092 [17:16<21:25, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23973.656778737903\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 72.67it/s]\n",
      " 41%|████      | 20502/50092 [17:20<3:03:35,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.773973518790959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 20998/50092 [17:43<24:32, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25148.667589143617\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 103.64it/s]\n",
      " 42%|████▏     | 21003/50092 [17:46<2:15:03,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7742410057509697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 21497/50092 [18:07<17:30, 27.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26040.23997230362\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 122.76it/s]\n",
      " 43%|████▎     | 21503/50092 [18:10<1:40:08,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7858766885114351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 21998/50092 [18:28<16:47, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26035.485811963677\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 122.83it/s]\n",
      " 44%|████▍     | 22004/50092 [18:31<1:37:38,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7845392537113816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 22496/50092 [18:49<13:56, 32.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23988.336805832572\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.23it/s]\n",
      " 45%|████▍     | 22503/50092 [18:51<1:26:40,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7726360839909054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 22998/50092 [19:09<15:56, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26652.039053791203\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.70it/s]\n",
      " 46%|████▌     | 23004/50092 [19:12<1:28:23,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7828005884713121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 23498/50092 [19:30<18:13, 24.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25566.475741248578\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7785207971111409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 23999/50092 [19:51<16:17, 26.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26552.754896767437\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 129.71it/s]\n",
      " 48%|████▊     | 24005/50092 [19:53<1:31:43,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7722348535508894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 24497/50092 [20:11<13:32, 31.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25423.034649144858\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 120.28it/s]\n",
      " 49%|████▉     | 24504/50092 [20:14<1:20:06,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7848067406713922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 24996/50092 [20:30<13:58, 29.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25822.576884657145\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.35it/s]\n",
      " 50%|████▉     | 25003/50092 [20:33<1:18:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7754446970710178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 25499/50092 [20:50<14:44, 27.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24882.04527053982\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 128.97it/s]\n",
      " 51%|█████     | 25502/50092 [20:53<1:52:33,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7785207971111409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 25998/50092 [21:10<14:46, 27.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26207.34909119457\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 129.39it/s]\n",
      " 52%|█████▏    | 26005/50092 [21:13<1:15:29,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7803932058312157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 26497/50092 [21:31<13:32, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25256.918834254146\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 119.87it/s]\n",
      " 53%|█████▎    | 26503/50092 [21:34<1:19:57,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7699612143907985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 26997/50092 [21:51<11:29, 33.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25263.017277918756\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 120.07it/s]\n",
      " 54%|█████▍    | 27004/50092 [21:54<1:14:29,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7806606927912264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 27499/50092 [22:12<13:40, 27.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25314.14016583562\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 127.09it/s]\n",
      " 55%|█████▍    | 27502/50092 [22:15<1:32:36,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7822656145512906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 27999/50092 [22:32<13:45, 26.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24295.2677433528\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 120.58it/s]\n",
      " 56%|█████▌    | 28004/50092 [22:35<1:26:11,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7849404841513976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 28499/50092 [22:52<11:25, 31.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25110.32811653614\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 121.83it/s]\n",
      " 57%|█████▋    | 28503/50092 [22:55<1:23:06,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7775845927511034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 28998/50092 [23:12<11:47, 29.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24431.043715640903\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 116.12it/s]\n",
      " 58%|█████▊    | 29005/50092 [23:15<1:07:27,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7829343319513173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 29499/50092 [23:32<13:00, 26.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25949.539173662663\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.18it/s]\n",
      " 59%|█████▉    | 29504/50092 [23:35<1:18:27,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7845392537113816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 29997/50092 [23:52<11:15, 29.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24272.821489192545\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 126.28it/s]\n",
      " 60%|█████▉    | 30004/50092 [23:55<1:01:01,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7937675538317507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 30499/50092 [24:11<10:00, 32.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24185.26563652605\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 112.91it/s]\n",
      " 61%|██████    | 30503/50092 [24:14<1:20:36,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7861441754714458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 30997/50092 [24:31<12:25, 25.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24499.471348680556\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 125.40it/s]\n",
      " 62%|██████▏   | 31004/50092 [24:34<1:02:46,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.782399358031296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 31497/50092 [24:51<09:38, 32.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24827.85122892633\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 121.66it/s]\n",
      " 63%|██████▎   | 31501/50092 [24:53<1:12:27,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7767821318710713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 31996/50092 [25:10<10:06, 29.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33165.53652923694\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 121.88it/s]\n",
      " 64%|██████▍   | 32004/50092 [25:13<53:07,  5.68it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7750434666310018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 32498/50092 [25:29<08:58, 32.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25263.976750765927\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 127.32it/s]\n",
      " 65%|██████▍   | 32505/50092 [25:32<53:14,  5.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7885515581115421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 32997/50092 [25:49<09:10, 31.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24341.693677412346\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 117.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7707636752708306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 33498/50092 [26:08<08:54, 31.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24468.611909657717\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 127.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7746422361909857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 33997/50092 [26:27<08:37, 31.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23864.104168925434\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.83it/s]\n",
      " 68%|██████▊   | 34005/50092 [26:30<45:20,  5.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7822656145512906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 34498/50092 [26:46<08:11, 31.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24444.955561190844\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 124.50it/s]\n",
      " 69%|██████▉   | 34502/50092 [26:49<59:48,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7830680754313227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 34998/50092 [27:06<08:21, 30.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24387.206754075363\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 118.74it/s]\n",
      " 70%|██████▉   | 35005/50092 [27:09<49:00,  5.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7807944362712318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 35498/50092 [27:26<08:30, 28.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25146.86635041237\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.44it/s]\n",
      " 71%|███████   | 35505/50092 [27:29<44:25,  5.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7965761669118631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 35998/50092 [27:45<07:26, 31.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23350.16490393877\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 126.10it/s]\n",
      " 72%|███████▏  | 36002/50092 [27:48<54:29,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.777852079711114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 36498/50092 [28:04<06:24, 35.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24651.25545847416\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.95it/s]\n",
      " 73%|███████▎  | 36502/50092 [28:07<49:56,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7763809014310552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 36998/50092 [28:23<06:46, 32.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24787.21558174584\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 122.34it/s]\n",
      " 74%|███████▍  | 37006/50092 [28:26<37:29,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7695599839507824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 37496/50092 [28:42<06:35, 31.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25700.036999884993\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.84it/s]\n",
      " 75%|███████▍  | 37503/50092 [28:45<37:55,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7718336231108733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 37996/50092 [29:01<07:11, 28.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24343.04919190705\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 123.70it/s]\n",
      " 76%|███████▌  | 38003/50092 [29:04<37:11,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7810619232312425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38144/50092 [29:08<09:07, 21.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-b55179e9a53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m        \u001b[0;31m#edge_index_seq_sent_neg = get_negative_edges_seq(train_dataset.nodes_map).to(dev)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m    \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#   save_model(model, 'freeze-embedding_noLang')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m    \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-30c04d4ca67a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, data_loader, max_batches)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     group['eps'])\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data_loader = DataLoader(gnn_dataset_train_pos, batch_size=1, shuffle=True)\n",
    "test_data_loader = DataLoader(gnn_dataset_blinker_pos, batch_size=1, shuffle=True)\n",
    "\n",
    "#features.append(afeatures.MappingFeature(len(postag_map), 'tag_priors'))\n",
    "channels = 512\n",
    "in_dim = sum(t.out_dim for t in features)\n",
    "##model.encoder.feature_encoder.feature_types.append(afeatures.MappingFeature(len(postag_map), 'tag_priors'))\n",
    "##model.encoder.feature_encoder.layers.append(afeatures.MappingEncoding(normalized_tag_frequencies, freeze=True))\n",
    "##model.encoder.conv1 = pyg_nn.GATConv(in_dim, 2*channels, heads= n_head)\n",
    "\n",
    "decoder_in_dim = n_head * channels \n",
    "decoder = POSDecoder(decoder_in_dim, decoder_in_dim*2, len(postag_map))\n",
    "model = pyg_nn.GAE(Encoder(in_dim, channels, features, n_head, edge_feature_dim=len([])), decoder).to(dev)\n",
    "freeze_encoders_embedding(model.encoder.feature_encoder)\n",
    "\n",
    "model.to(dev)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"model params - decoder params - conv1\", sum(p.numel() for p in model.parameters()), sum(p.numel() for p in decoder.parameters()))\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "   print(f\"\\n----------------epoch {epoch} ---------------\")\n",
    "    \n",
    "   #if epoch % 1 == 0:\n",
    "   #    train_neg_edge_index = gutils.get_negative_edges(train_verses, small_editions, train_dataset.nodes_map,  verse_alignments_inter).to(dev)\n",
    "       #edge_index_seq_sent_neg = get_negative_edges_seq(train_dataset.nodes_map).to(dev)\n",
    "\n",
    "   train(epoch, train_data_loader)\n",
    "#   save_model(model, 'freeze-embedding_noLang')\n",
    "   test(epoch, test_data_loader) \n",
    "   clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yoruba_postags(dataset, gnn_dataset, data_loader):\n",
    "    edit ='yor-x-bible-2010'\n",
    "\n",
    "    model.eval()\n",
    "    res = {}\n",
    "    data_endoer = DataEncoder(data_loader, model)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for z, verse, _, _ in data_endoer:\n",
    "            if verse in dataset.nodes_map[edit]:\n",
    "\n",
    "                index = []\n",
    "                toks = list(dataset.nodes_map[edit][verse].keys())\n",
    "                for i in toks:\n",
    "                    index.append(dataset.nodes_map[edit][verse][i])\n",
    "                index = torch.LongTensor(index).to(dev) - gnn_dataset.verse_info[verse]['padding']\n",
    "\n",
    "                preds = model.decoder(z, index)\n",
    "\n",
    "                _, predicted = torch.max(preds, 1)\n",
    "\n",
    "                res[verse] = {toks[i]:predicted[i].item() for i in range(len(toks))}\n",
    "\n",
    "    return res\n",
    "\n",
    "yoruba_pos_tags = {}\n",
    "res_ = get_yoruba_postags(train_dataset, gnn_dataset_train_pos, DataLoader(gnn_dataset_train_pos, batch_size=1, shuffle=False))\n",
    "yoruba_pos_tags.update(res_)\n",
    "\n",
    "res_ = get_yoruba_postags(heb_test_dataset, gnn_dataset_heb_pos, DataLoader(gnn_dataset_heb_pos, batch_size=1, shuffle=False))\n",
    "yoruba_pos_tags.update(res_)\n",
    "\n",
    "res_ = get_yoruba_postags(grc_test_dataset, gnn_dataset_grc_pos, DataLoader(gnn_dataset_grc_pos, batch_size=1, shuffle=False))\n",
    "yoruba_pos_tags.update(res_)\n",
    "\n",
    "res_ = get_yoruba_postags(blinker_test_dataset, gnn_dataset_blinker_pos, DataLoader(gnn_dataset_blinker_pos, batch_size=1, shuffle=False))\n",
    "yoruba_pos_tags.update(res_)\n",
    "\n",
    "torch.save(yoruba_pos_tags, '/mounts/work/ayyoob/results/gnn_align/yoruba/pos_tags_freeze-embedding_noLang.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yoruba_pos_tags.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global model, decoder\n",
    "#1/0\n",
    "\n",
    "decoder = None\n",
    "model = None\n",
    "\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 1, 'out_dim': 20, 'global_normalize': False, 'name': 'edit_f', 'Active': True, 'n_classes': 83}\n",
      "{'type': 1, 'out_dim': 32, 'global_normalize': False, 'name': 'position', 'Active': True, 'n_classes': 150}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': '{centrality_type}', 'Active': True}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': '{centrality_type}', 'Active': True}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': '{centrality_type}', 'Active': True}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': '{centrality_type}', 'Active': True}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': '{centrality_type}', 'Active': True}\n",
      "{'type': 1, 'out_dim': 32, 'global_normalize': False, 'name': '{name}', 'Active': True, 'n_classes': 200}\n",
      "{'type': 1, 'out_dim': 32, 'global_normalize': False, 'name': '{name}', 'Active': True, 'n_classes': 200}\n",
      "{'type': 6, 'out_dim': 100, 'global_normalize': False, 'name': 'word', 'Active': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = blinker_test_dataset.features[:]\n",
    "#features_edge = train_dataset.features_edge[:]\n",
    "from pprint import pprint\n",
    "#print('indim',in_dim)\n",
    "#features[-1].out_dim = 50\n",
    "for i in features:\n",
    "    #if i.type==3:\n",
    "    #    i.out_dim=4\n",
    "    print(vars(i))\n",
    "\n",
    "#sum(p.out_dim for p in features)\n",
    "#train_dataset.features.pop()\n",
    "#train_dataset.features[0] = afeatures.OneHotFeature(20, 83, 'editf')\n",
    "#train_dataset.features[1] = afeatures.OneHotFeature(32, 150, 'position')\n",
    "#train_dataset.features[2] = afeatures.FloatFeature(4, 'degree_centrality')\n",
    "#train_dataset.features[3] = afeatures.FloatFeature(4, 'closeness_centrality')\n",
    "#train_dataset.features[4] = afeatures.FloatFeature(4, 'betweenness_centrality')\n",
    "#train_dataset.features[5] = afeatures.FloatFeature(4, 'load_centrality')\n",
    "#train_dataset.features[6] = afeatures.FloatFeature(4, 'harmonic_centrality')\n",
    "#train_dataset.features[7] = afeatures.OneHotFeature(32, 250, 'greedy_modularity_community')\n",
    "##train_dataset.features.append(afeatures.MappingFeature(100, 'word'))\n",
    "#torch.save(train_dataset, \"/mounts/work/ayyoob/models/gnn/dataset_helfi_train_community_word.pickle\")\n",
    "#torch.save(train_dataset.features[-3], \"./features.tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_map = train_dataset.nodes_map\n",
    "bad_edition_files = []\n",
    "for edit in nodes_map:\n",
    "    bad_count = 0\n",
    "    for verse in nodes_map[edit]:\n",
    "        if len(nodes_map[edit][verse].keys()) < 2:\n",
    "            bad_count += 1\n",
    "        if bad_count > 1:\n",
    "            bad_edition_files.append(edit)\n",
    "            break\n",
    "print(bad_edition_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_japanese_nodes = set()\n",
    "nodes_map = train_dataset.nodes_map\n",
    "\n",
    "for bad_editionf in bad_edition_files:\n",
    "    for verse in nodes_map[bad_editionf]:\n",
    "        for item in nodes_map[bad_editionf][verse].items():\n",
    "            all_japanese_nodes.add(item[1])\n",
    "\n",
    "print(\" all japansese nodes: \", len(all_japanese_nodes))\n",
    "edge_index = train_dataset.edge_index.to('cpu')\n",
    "remaining_edges_index = []\n",
    "for i in tqdm(range(0, edge_index.shape[1], 2)):\n",
    "    if edge_index[0, i].item() not in all_japanese_nodes and edge_index[0, i+1].item() not in all_japanese_nodes:\n",
    "        remaining_edges_index.extend([i, i+1])\n",
    "\n",
    "print('original total edges count', edge_index.shape)\n",
    "print('remaining edge count', len(remaining_edges_index))\n",
    "train_dataset.edge_index = edge_index[:, remaining_edges_index]\n",
    "train_dataset.edge_index.shape\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aab640873abb67ad450730b814c8d7de015aa287a6fc3bae4b7154b533e57676"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('multalign_graph': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
